{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712753df",
   "metadata": {},
   "source": [
    "# Phase 0: Hello BigQuery AI\n",
    "This notebook demonstrates minimal embedding + vector search + optional text generation using BigQuery AI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & environment configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ID = os.getenv('BQ_PROJECT_ID', 'bq_project_northstar')\n",
    "DATASET = os.getenv('BQ_DATASET', 'demo_ai')\n",
    "LOCATION = os.getenv('BQ_LOCATION', 'US')\n",
    "EMBED_MODEL = os.getenv('BQ_EMBED_MODEL', 'text-embedding-004')\n",
    "GEN_MODEL = os.getenv('BQ_GEN_MODEL', 'gemini-1.5-pro')\n",
    "TOP_K = 5\n",
    "print('Config:', PROJECT_ID, DATASET, LOCATION, EMBED_MODEL, GEN_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fa6467",
   "metadata": {},
   "source": [
    "## (Optional) Authentication\n",
    "If running on Kaggle with BigQuery integration, auth is implicit. Else uncomment the service account block below and provide a JSON file path in env `BQ_SERVICE_ACCOUNT_JSON`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b82044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional service account auth (commented)\n",
    "# from google.cloud import bigquery\n",
    "# import json, os\n",
    "# sa_json = os.getenv('BQ_SERVICE_ACCOUNT_JSON')\n",
    "# if sa_json and Path(sa_json).exists():\n",
    "#     os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = sa_json\n",
    "# client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaaa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset if not exists and base table with sample texts\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=PROJECT_ID, location=LOCATION)\n",
    "client.create_dataset(f'{PROJECT_ID}.{DATASET}', exists_ok=True)\n",
    "rows = [\n",
    "    (1, 'Login page returns 500 after password reset.'),\n",
    "    (2, 'Image upload fails: content-type mismatch.'),\n",
    "    (3, 'DB connection timeout in staging during deploy.'),\n",
    "    (4, 'Checkout error: stripe webhook signature invalid.'),\n",
    "    (5, 'Search results empty when filters combined.'),\n",
    "    (6, 'Mobile app crash on Android 14, camera permission.'),\n",
    "    (7, 'TLS certificate expired on edge gateway.'),\n",
    "    (8, 'Cron job skipped due to timezone change.'),\n",
    "]\n",
    "\n",
    "schema = [bigquery.SchemaField('id','INT64'), bigquery.SchemaField('text','STRING')]\n",
    "table_id = f'{PROJECT_ID}.{DATASET}.demo_texts'\n",
    "try:\n",
    "    table = client.create_table(bigquery.Table(table_id, schema=schema))\n",
    "except Exception:\n",
    "    table = client.get_table(table_id)\n",
    "if client.get_table(table_id).num_rows == 0:\n",
    "    errors = client.insert_rows(table, rows)\n",
    "    assert not errors, errors\n",
    "print('Base table ready; rows:', client.get_table(table_id).num_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run embeddings SQL to materialize demo_texts_emb\n",
    "from pathlib import Path\n",
    "EMBED_SQL_PATH = Path('sql/embeddings.sql')\n",
    "sql_src = EMBED_SQL_PATH.read_text()\n",
    "rendered = (sql_src\n",
    "    .replace('${PROJECT_ID}', PROJECT_ID)\n",
    "    .replace('${DATASET}', DATASET)\n",
    "    .replace('${EMBED_MODEL}', EMBED_MODEL)\n",
    "    .replace('${SOURCE_TABLE}', 'demo_texts')\n",
    ")\n",
    "job = client.query(rendered)\n",
    "job.result()\n",
    "print('Embeddings table created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect embedded table\n",
    "e_emb = client.get_table(f'{PROJECT_ID}.{DATASET}.demo_texts_emb')\n",
    "print('Embedded rows:', e_emb.num_rows)\n",
    "preview = client.query(\n",
    "    f'SELECT id, ARRAY_LENGTH(embedding) AS dim FROM `{PROJECT_ID}.{DATASET}.demo_texts_emb` LIMIT 3'\n",
    ").to_dataframe()\n",
    "preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector search for a sample query\n",
    "VS_SQL_PATH = Path('sql/vector_search.sql')\n",
    "vs_src = VS_SQL_PATH.read_text()\n",
    "vs_rendered = (vs_src\n",
    "    .replace('${PROJECT_ID}', PROJECT_ID)\n",
    "    .replace('${DATASET}', DATASET)\n",
    "    .replace('${EMBED_MODEL}', EMBED_MODEL)\n",
    "    .replace('${QUERY_TEXT}', \"'login error after reset'\")\n",
    "    .replace('${TOP_K}', str(TOP_K))\n",
    ")\n",
    "vs_df = client.query(vs_rendered).to_dataframe()\n",
    "vs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional text generation classification\n",
    "GEN_SQL_PATH = Path('sql/generate_text.sql')\n",
    "gen_src = GEN_SQL_PATH.read_text()\n",
    "gen_rendered = (gen_src\n",
    "    .replace('${PROJECT_ID}', PROJECT_ID)\n",
    "    .replace('${DATASET}', DATASET)\n",
    "    .replace('${GEN_MODEL}', GEN_MODEL)\n",
    "    .replace('${LIMIT}', '3')\n",
    ")\n",
    "gen_df = client.query(gen_rendered).to_dataframe()\n",
    "gen_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc10c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run verifier to confirm required ML constructs\n",
    "from src import verifier as v_mod\n",
    "ok = v_mod.verify_sql_directory(Path('sql'))\n",
    "print('Verifier result:', ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2797199",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We created a demo dataset, generated embeddings, performed vector search, and optionally classified rows with text generation. Next: vector index + triage loop (Phase 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822101c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. SQL Loader & Execution Helpers\n",
    "\n",
    "def load_sql(name: str) -> str:\n",
    "    path = SQL_DIR / name\n",
    "    return path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def render_sql(template: str, params: dict[str, Any]) -> str:\n",
    "    sql = template\n",
    "    for k, v in params.items():\n",
    "        sql = sql.replace(f\"${{${k}}}\", v)\n",
    "    return sql\n",
    "\n",
    "\n",
    "def run_query(sql: str):\n",
    "    if not bigquery:\n",
    "        print(\"(skip) bigquery lib not available\")\n",
    "        return []\n",
    "    job = client.query(sql)\n",
    "    return list(job)\n",
    "\n",
    "\n",
    "def dry_run(sql: str) -> int:\n",
    "    if not bigquery:\n",
    "        return 0\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    job = client.query(sql, job_config=job_config)\n",
    "    return job.total_bytes_processed  # type: ignore[attr-defined]\n",
    "\n",
    "print(\"Helpers ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef786071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inspect Source Data (placeholder)\n",
    "print(\"TODO: Preview source tables once dataset is populated.\")\n",
    "\n",
    "# 6. Generate Embeddings (ML.GENERATE_EMBEDDING) (placeholder)\n",
    "print(\"TODO: Execute embeddings.sql with parameters.\")\n",
    "\n",
    "# 7. Persist Embeddings Table (placeholder)\n",
    "print(\"TODO: CREATE OR REPLACE target embeddings table.\")\n",
    "\n",
    "# 8. Create / Use Vector Index (placeholder)\n",
    "print(\"TODO: Demonstrate index creation or document exact search.\")\n",
    "\n",
    "# 9. Vector Search (VECTOR_SEARCH) (placeholder)\n",
    "print(\"TODO: Run vector_search.sql and display results.\")\n",
    "\n",
    "# 10. End-to-End Retrieval Pipeline (GraphRAG) (placeholder)\n",
    "print(\"TODO: Implement multi-hop retrieval in retrieval module.\")\n",
    "\n",
    "# 11. Augmented Generation Demo (placeholder)\n",
    "print(\"TODO: Compose context + call model or placeholder generator.\")\n",
    "\n",
    "# 12. Evaluation & Verification Checks (placeholder)\n",
    "print(\"TODO: Execute verifier functions and summarize.\")\n",
    "\n",
    "# 13. CLI Integration Example (placeholder)\n",
    "print(\"TODO: Invoke CLI retrieval command via subprocess.\")\n",
    "\n",
    "# 14. Resource & Cost Monitoring (placeholder)\n",
    "print(\"TODO: Track dry run bytes and actual bytes in a dataframe.\")\n",
    "\n",
    "# 15. Cleanup Temporary Assets (placeholder)\n",
    "print(\"TODO: Drop temp tables / datasets if created.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
