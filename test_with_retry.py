#!/usr/bin/env python3
"""Test text models with retry logic for IAM propagation delays."""

import time
from config import load_env
from google.cloud import bigquery

load_env()

def test_text_generation_with_retry(max_retries=3, delay_seconds=30):
    """Test text generation with retry logic for IAM delays."""
    client = bigquery.Client()
    project_id = "gleaming-bus-468914-a6"
    
    sql = f"""
    CREATE OR REPLACE MODEL `{project_id}.demo_ai_east1.text_model`
    REMOTE WITH CONNECTION `{project_id}.us-east1.vertex-ai-east1`
    OPTIONS (
      ENDPOINT = 'gemini-1.5-pro'
    )
    """
    
    for attempt in range(max_retries):
        try:
            print(f"üîÑ Attempt {attempt + 1}/{max_retries}: Creating text model...")
            job = client.query(sql)
            job.result()
            print("‚úÖ Text model created successfully!")
            
            # Test generation
            test_sql = f"""
            SELECT * FROM ML.GENERATE_TEXT(
                MODEL `{project_id}.demo_ai_east1.text_model`,
                (SELECT 'Write a short hello message' as prompt),
                STRUCT(50 as max_output_tokens, 0.8 as temperature)
            )
            """
            
            print("Testing text generation...")
            result = client.query(test_sql)
            for row in result:
                generated = row.ml_generate_text_result
                print(f"‚úÖ Generated text: {generated}")
                break
            
            print("\nüéâ SUCCESS! Text generation is working!")
            return True
            
        except Exception as e:
            error_msg = str(e)
            print(f"‚ùå Attempt {attempt + 1} failed: {error_msg[:100]}...")
            
            if "permission" in error_msg.lower() and attempt < max_retries - 1:
                print(f"‚è≥ IAM may still be propagating. Waiting {delay_seconds} seconds...")
                time.sleep(delay_seconds)
            elif "not found" in error_msg.lower() and "model" in error_msg.lower():
                print("üîç Trying alternative model endpoints...")
                # Try different models
                alternatives = ['gemini-pro', 'text-bison', 'gemini-1.0-pro']
                for alt_model in alternatives:
                    if test_alternative_model(client, project_id, alt_model):
                        return True
                break
            else:
                if attempt == max_retries - 1:
                    print(f"\n‚ùå All attempts failed. Final error: {error_msg}")
                break
    
    return False

def test_alternative_model(client, project_id, model_endpoint):
    """Test alternative model endpoints."""
    try:
        print(f"üîÑ Trying alternative model: {model_endpoint}")
        sql = f"""
        CREATE OR REPLACE MODEL `{project_id}.demo_ai_east1.text_model_alt`
        REMOTE WITH CONNECTION `{project_id}.us-east1.vertex-ai-east1`
        OPTIONS (
          ENDPOINT = '{model_endpoint}'
        )
        """
        
        job = client.query(sql)
        job.result()
        print(f"‚úÖ Alternative model {model_endpoint} created!")
        
        # Test generation
        test_sql = f"""
        SELECT * FROM ML.GENERATE_TEXT(
            MODEL `{project_id}.demo_ai_east1.text_model_alt`,
            (SELECT 'Hello' as prompt),
            STRUCT(30 as max_output_tokens)
        )
        """
        
        result = client.query(test_sql)
        for row in result:
            generated = row.ml_generate_text_result
            print(f"‚úÖ {model_endpoint} generated: {generated}")
            break
        
        return True
        
    except Exception as e:
        print(f"‚ùå {model_endpoint} failed: {str(e)[:80]}...")
        return False

def main():
    print("üß™ Testing Text Generation in us-east1")
    print("=" * 50)
    print("Service Account: bqcx-111337406730-4igi@gcp-sa-bigquery-condel.iam.gserviceaccount.com")
    print("Expected Role: Vertex AI User")
    print("Region: us-east1")
    print()
    
    success = test_text_generation_with_retry()
    
    if success:
        print("\nüéâ FINAL SUCCESS!")
        print("‚úÖ Text generation models are now working in us-east1!")
        print("‚úÖ You now have both:")
        print("   ‚Ä¢ Embeddings in US region (demo_ai dataset)")
        print("   ‚Ä¢ Text generation in us-east1 region (demo_ai_east1 dataset)")
    else:
        print("\n‚ùå Text generation setup incomplete")
        print("üí° You still have working embeddings in the US region")
        print("üí° Consider using embedding-only features for now")

if __name__ == "__main__":
    main()
